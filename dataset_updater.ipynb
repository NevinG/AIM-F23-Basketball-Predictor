{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATL\n",
      "BOS\n",
      "BRK\n",
      "CHO\n",
      "CHI\n",
      "CLE\n",
      "DAL\n",
      "DEN\n",
      "DET\n",
      "GSW\n",
      "HOU\n",
      "IND\n",
      "LAC\n",
      "LAL\n",
      "MEM\n",
      "MIA\n",
      "MIL\n",
      "MIN\n",
      "NOP\n",
      "NYK\n",
      "OKC\n",
      "ORL\n",
      "PHI\n",
      "PHO\n",
      "POR\n",
      "SAC\n",
      "SAS\n",
      "TOR\n",
      "UTA\n",
      "WAS\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "teams = [\n",
    "    'ATL', 'BOS', 'BRK', 'CHO', 'CHI', 'CLE', \n",
    "    'DAL', 'DEN', 'DET', 'GSW', 'HOU', 'IND', \n",
    "    'LAC', 'LAL', 'MEM', 'MIA', 'MIL', 'MIN', \n",
    "    'NOP', 'NYK', 'OKC', 'ORL', 'PHI', 'PHO',\n",
    "    'POR', 'SAC', 'SAS', 'TOR', 'UTA', 'WAS'\n",
    "    ]\n",
    "\n",
    "column_headers = ['Date', 'H/A', 'Opp', 'W/L', 'P', 'OppP', 'FG', 'FGA', 'FG%', '3P',\n",
    "       '3PA', '3P%', 'FT', 'FTA', 'FT%', 'ORB', 'TRB', 'AST', 'STL', 'BLK',\n",
    "       'TOV', 'PF', 'ORtg', 'DRtg', 'Pace', 'FTr', '3PAr', 'TS%', 'TRB%',\n",
    "       'AST%', 'STL%', 'BLK%', 'OeFG%', 'OTOV%', 'OORB%', 'OFT/FGA', 'DeFG%',\n",
    "       'DTOV%', 'DDRB%', 'DFT/FGA']\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "for team in teams:\n",
    "    #this is so our requests dont get timed out\n",
    "    print(team)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #GET current df\n",
    "    df = pd.read_csv('./data/' + team + '.csv')\n",
    "    df = df.drop(df.columns[[0]],axis = 1)\n",
    "\n",
    "    #create a new df\n",
    "    new_df = pd.DataFrame(columns=column_headers)\n",
    "\n",
    "    #get data of most recent entry in the .csv\n",
    "    most_recent_date = df.iloc[df.shape[0] - 1]['Date']\n",
    "    most_recent_date_object = datetime.strptime(most_recent_date, '%Y-%m-%d').date()\n",
    "\n",
    "    #GET normal data not advanced\n",
    "    URL = 'https://www.basketball-reference.com/teams/' + team + '/2024/gamelog/'\n",
    "    page = requests.get(URL)\n",
    "    delay = page.headers.get(\"Retry-After\", \"None\")\n",
    "\n",
    "    if delay != \"None\":\n",
    "        d = datetime.now()\n",
    "        d = d + timedelta(0, int(delay))\n",
    "        print(\"Try again at : \")\n",
    "        print(d)\n",
    "        break\n",
    "    \n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    table = soup.find(\"table\")\n",
    "\n",
    "    table_body = table.find('tbody')\n",
    "\n",
    "    rows = table_body.find_all('tr')\n",
    "\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "\n",
    "        #make sure this column is a new column not in the dataset\n",
    "        date = cols[1]\n",
    "        date_object = datetime.strptime(date, '%Y-%m-%d').date()\n",
    "        if date_object <= most_recent_date_object:\n",
    "            break\n",
    "        \n",
    "        \n",
    "        #sanitize this col\n",
    "        cols.pop(0)\n",
    "        cols[1] = 'A' if cols[1] == '@' else 'H'\n",
    "        cols.pop(22)\n",
    "        cols = cols[:22]\n",
    "\n",
    "        #add to the df\n",
    "        column_head = ['Date', 'H/A', 'Opp', 'W/L', 'P', 'OppP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', 'FT', 'FTA', 'FT%', 'ORB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF']\n",
    "        new_df = pd.concat([new_df,pd.DataFrame([cols], columns=column_head)])\n",
    "\n",
    "    #GET advanced data not normal\n",
    "    URL = 'https://www.basketball-reference.com/teams/' + team + '/2024/gamelog-advanced/'\n",
    "    page = requests.get(URL)\n",
    "\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    table = soup.find(\"table\")\n",
    "    \n",
    "    table_body = table.find('tbody')\n",
    "\n",
    "    rows = table_body.find_all('tr')\n",
    "\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "\n",
    "        #make sure this column is a new column not in the dataset\n",
    "        date = cols[1]\n",
    "        date_object = datetime.strptime(date, '%Y-%m-%d').date()\n",
    "        if date_object <= most_recent_date_object:\n",
    "            break\n",
    "        \n",
    "        \n",
    "        #sanitize this col\n",
    "        cols.pop(0)\n",
    "        cols.pop(1)\n",
    "        cols.pop(1)\n",
    "        cols.pop(1)\n",
    "        cols.pop(13)\n",
    "        cols.pop(17)\n",
    "        cols.pop(1)\n",
    "        cols.pop(1)\n",
    "        cols.pop(0)\n",
    "        \n",
    "        #add to the df\n",
    "        column_head = ['ORtg', 'DRtg', 'Pace', 'FTr', '3PAr', 'TS%', 'TRB%',\n",
    "       'AST%', 'STL%', 'BLK%', 'OeFG%', 'OTOV%', 'OORB%', 'OFT/FGA', 'DeFG%',\n",
    "       'DTOV%', 'DDRB%', 'DFT/FGA']\n",
    "\n",
    "        #find index of date\n",
    "        new_df.loc[new_df['Date'] == date, column_head] = cols\n",
    "\n",
    "    #add new_df to df\n",
    "    df = pd.concat([df, new_df])\n",
    "    \n",
    "\n",
    "    #save to .csv\n",
    "    df.to_csv(\"./data/\" + team + \".csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates current_team_data.csv\n",
    "dataset_df = pd.DataFrame()\n",
    "\n",
    "for team in teams:\n",
    "    df = pd.read_csv('./data/' + team + '.csv')\n",
    "        \n",
    "    #calculate average over last 3 games\n",
    "    wins_last_3 = df.iloc[-3:]['W/L'].value_counts().get('W', 0)\n",
    "    home_last_3 = df.iloc[-3:]['H/A'].value_counts().get('H', 0)\n",
    "    numerical_stats_last_3 = df.iloc[-3:,5:].mean().apply(lambda x: float(\"{:.2f}\".format(x)))\n",
    "    last_3 = numerical_stats_last_3\n",
    "    last_3['W'] = wins_last_3\n",
    "    last_3['H'] = home_last_3\n",
    "    last_3.index = list(map(lambda n: \"last_3_\" + n, last_3.index.to_list()))\n",
    "    \n",
    "    #calculate average over last 10 games\n",
    "    wins_last_10 = df.iloc[-10:]['W/L'].value_counts().get('W', 0)\n",
    "    home_last_10 = df.iloc[-10:]['H/A'].value_counts().get('H', 0)\n",
    "    numerical_stats_last_10 = df.iloc[-10:,5:].mean().apply(lambda x: float(\"{:.2f}\".format(x)))\n",
    "    last_10 = numerical_stats_last_10\n",
    "    last_10['W'] = wins_last_10\n",
    "    last_10['H'] = home_last_10\n",
    "    last_10.index = list(map(lambda n: \"last_10_\" + n, last_10.index.to_list()))\n",
    "\n",
    "    #calculate average over last 50 games\n",
    "    wins_last_50 = df.iloc[-50:]['W/L'].value_counts().get('W', 0)\n",
    "    home_last_50 = df.iloc[-50:]['H/A'].value_counts().get('H', 0)\n",
    "    numerical_stats_last_50 = df.iloc[-50:,5:].mean().apply(lambda x: float(\"{:.2f}\".format(x)))\n",
    "    last_50 = numerical_stats_last_50\n",
    "    last_50['W'] = wins_last_50\n",
    "    last_50['H'] = home_last_50\n",
    "    last_50.index = list(map(lambda n: \"last_50_\" + n, last_50.index.to_list()))\n",
    "    #add all averages to one series\n",
    "    stats = pd.concat([pd.Series([team], index=[\"Team\"]),last_3, last_10, last_50])\n",
    "\n",
    "    #add stats to the dataset\n",
    "    dataset_df = pd.concat([dataset_df, stats.to_frame().T])\n",
    "\n",
    "#save data\n",
    "dataset_df.to_csv('./data/current_team_data.csv')\n",
    "\n",
    "\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SANITIZES ISSUE OF UNAMED COLUMN HEADERS\n",
    "#DONT NEED TO RUN THIS FILE\n",
    "\n",
    "# teams = [\n",
    "#     'ATL', 'BOS', 'BRK', 'CHO', 'CHI', 'CLE', \n",
    "#     'DAL', 'DEN', 'DET', 'GSW', 'HOU', 'IND', \n",
    "#     'LAC', 'LAL', 'MEM', 'MIA', 'MIL', 'MIN', \n",
    "#     'NOP', 'NYK', 'OKC', 'ORL', 'PHI', 'PHO',\n",
    "#     'POR', 'SAC', 'SAS', 'TOR', 'UTA', 'WAS'\n",
    "#     ]\n",
    "\n",
    "# for team in teams:\n",
    "#     df = pd.read_csv('./data/' + team + '.csv')\n",
    "\n",
    "#     cols = df.columns\n",
    "#     col_nums = []\n",
    "#     for i in range(len(cols)):\n",
    "#         if \"Unnamed\" in cols[i]:\n",
    "#             col_nums.append(i)\n",
    "#     #drop unneeded columns\n",
    "#     df = df.drop(df.columns[col_nums],axis = 1)\n",
    "#     #save\n",
    "#     df.to_csv(\"./data/\" + team + \".csv\")\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
